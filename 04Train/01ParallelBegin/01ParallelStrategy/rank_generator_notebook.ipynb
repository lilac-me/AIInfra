{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6d9f0a0",
   "metadata": {},
   "source": [
    "# 导入必要的库\n",
    "本笔记本演示了如何使用Python进行模型并行组的初始化。首先，我们导入类型注解和参数解析所需的模块。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bbecb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional, Callable\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafb4976",
   "metadata": {},
   "source": [
    "# 定义工具函数\n",
    "以下函数用于并行组计算所需的数学操作，包括`prefix_product`、`inner_product`和`decompose`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71787097",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "# 工具函数：用于并行组的数学计算\n",
    "\n",
    "def prefix_product(a: List[int], init=1) -> List[int]:\n",
    "    \"\"\"\n",
    "    计算前缀积。例如 a=[2,3,4]，返回[1,2,6,24]。\n",
    "    用于计算每个维度的步长（stride），方便后续索引展开。\n",
    "    参数：\n",
    "        a: 并行维度列表，如[tp, dp, pp]\n",
    "        init: 初始值，默认为1\n",
    "    返回：\n",
    "        前缀积列表\n",
    "    \"\"\"\n",
    "    r = [init]\n",
    "    for v in a:\n",
    "        init = init * v\n",
    "        r.append(init)\n",
    "    return r\n",
    "\n",
    "def inner_product(a: List[int], b: List[int]) -> int:\n",
    "    \"\"\"\n",
    "    计算两个列表的内积。用于将多维索引转换为一维rank编号。\n",
    "    参数：\n",
    "        a: 索引列表\n",
    "        b: 步长列表\n",
    "    返回：\n",
    "        内积结果\n",
    "    \"\"\"\n",
    "    return sum([x * y for x, y in zip(a, b)])\n",
    "\n",
    "def decompose(index, shape, stride=None):\n",
    "    \"\"\"\n",
    "    将一维索引分解为多维索引。\n",
    "    例如：index=5, shape=[2,3], stride=[1,2]，返回[1,2]。\n",
    "    参数：\n",
    "        index: 一维索引\n",
    "        shape: 每个维度的大小\n",
    "        stride: 每个维度的步长（可选，默认自动计算）\n",
    "    返回：\n",
    "        多维索引列表\n",
    "    \"\"\"\n",
    "    if stride is None:\n",
    "        stride = prefix_product(shape)\n",
    "    idx = [(index // d) % s for s, d in zip(shape, stride)]\n",
    "    # 校验分解结果是否正确\n",
    "    assert (\n",
    "        sum([x * y for x, y in zip(idx, stride[:-1])]) == index\n",
    "    ), f\"idx {index} with shape {shape} mismatch the return idx {idx}\"\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e42107",
   "metadata": {},
   "source": [
    "# 定义RankGenerator类\n",
    "`RankGenerator`类用于生成不同并行模式下的rank分组，包括张量、流水线、数据、专家和上下文并行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613fdaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成并行组的核心函数和类\n",
    "\n",
    "def generate_masked_orthogonal_rank_groups(\n",
    "    world_size: int, parallel_size: List[int], mask: List[bool]\n",
    ") -> List[List[int]]:\n",
    "    \"\"\"\n",
    "    根据并行维度和掩码生成正交并行组。\n",
    "    参数：\n",
    "        world_size: 总rank数量（如总GPU数）\n",
    "        parallel_size: 各并行类型的大小列表，如[tp, dp, pp]\n",
    "        mask: 掩码，True表示该维度参与分组，False表示不参与\n",
    "    返回：\n",
    "        并行组列表，每组为rank编号列表\n",
    "    \"\"\"\n",
    "    masked_shape = [s for s, m in zip(parallel_size, mask) if m]  # 参与分组的维度\n",
    "    unmasked_shape = [s for s, m in zip(parallel_size, mask) if not m]  # 未参与分组的维度\n",
    "    global_stride = prefix_product(parallel_size)\n",
    "    masked_stride = [d for d, m in zip(global_stride, mask) if m]\n",
    "    unmasked_stride = [d for d, m in zip(global_stride, mask) if not m]\n",
    "    group_size = prefix_product(masked_shape)[-1]  # 每组包含的rank数量\n",
    "    num_of_group = world_size // group_size  # 总组数\n",
    "    ranks = []\n",
    "    for group_index in range(num_of_group):\n",
    "        decomposed_group_idx = decompose(group_index, unmasked_shape)  # 未参与分组的多维索引\n",
    "        rank = []\n",
    "        for rank_in_group in range(group_size):\n",
    "            decomposed_rank_idx = decompose(rank_in_group, masked_shape)  # 参与分组的多维索引\n",
    "            rank.append(\n",
    "                inner_product(decomposed_rank_idx, masked_stride)\n",
    "                + inner_product(decomposed_group_idx, unmasked_stride)\n",
    "            )\n",
    "        ranks.append(rank)\n",
    "    return ranks\n",
    "\n",
    "class RankGenerator(object):\n",
    "    \"\"\"\n",
    "    用于生成不同并行模式下的rank分组。\n",
    "    支持张量、数据、流水线、专家、上下文等多种并行类型。\n",
    "    \"\"\"\n",
    "    def __init__(self, tp: int, ep: int, dp: int, pp: int, cp: int, order: str, rank_offset: int = 0) -> None:\n",
    "        \"\"\"\n",
    "        初始化RankGenerator。\n",
    "        参数：\n",
    "            tp: 张量并行大小\n",
    "            ep: 专家并行大小\n",
    "            dp: 数据并行大小\n",
    "            pp: 流水线并行大小\n",
    "            cp: 上下文并行大小\n",
    "            order: 并行类型顺序（如'tp-dp-pp'）\n",
    "            rank_offset: rank偏移量（用于多模块拼接）\n",
    "        \"\"\"\n",
    "        assert (\n",
    "            ep == 1 or cp == 1\n",
    "        ), \"EP和CP不能同时大于1。CP只在默认RankGenerator中，EP只在专家RankGenerator中。\"\n",
    "        self.tp = tp\n",
    "        self.ep = ep\n",
    "        self.dp = dp\n",
    "        self.pp = pp\n",
    "        self.cp = cp\n",
    "        self.rank_offset = rank_offset\n",
    "        self.world_size = tp * dp * pp * cp * ep  # 总rank数\n",
    "        self.name_to_size = {\n",
    "            \"tp\": self.tp,\n",
    "            \"pp\": self.pp,\n",
    "            \"dp\": self.dp,\n",
    "            \"ep\": self.ep,\n",
    "            \"cp\": self.cp,\n",
    "        }\n",
    "        self.order = order\n",
    "        order = order.lower()\n",
    "        # 检查顺序中是否包含所有并行类型\n",
    "        for name in self.name_to_size.keys():\n",
    "            if name not in order and self.name_to_size[name] != 1:\n",
    "                raise RuntimeError(\n",
    "                    f\"并行类型({name})的大小为({self.name_to_size[name]})，但未在顺序({self.order})中指定。\"\n",
    "                )\n",
    "            elif name not in order:\n",
    "                order = order + '-' + name\n",
    "        self.order = order\n",
    "        self.ordered_size = []\n",
    "        for token in order.split('-'):\n",
    "            self.ordered_size.append(self.name_to_size[token])\n",
    "    def get_mask(self, order: str, token: str):\n",
    "        \"\"\"\n",
    "        根据顺序和目标类型生成掩码。\n",
    "        参数：\n",
    "            order: 并行类型顺序（如'tp-dp-pp'）\n",
    "            token: 需要分组的类型（如'tp-dp'）\n",
    "        返回：\n",
    "            掩码列表\n",
    "        \"\"\"\n",
    "        ordered_token = order.split('-')\n",
    "        token_list = token.split('-')\n",
    "        mask = [False] * len(ordered_token)\n",
    "        for t in token_list:\n",
    "            mask[ordered_token.index(t)] = True\n",
    "        return mask\n",
    "    def get_ranks(self, token):\n",
    "        \"\"\"\n",
    "        获取指定类型的rank分组。\n",
    "        参数：\n",
    "            token: 需要分组的类型（如'tp-dp'）\n",
    "        返回：\n",
    "            rank分组列表\n",
    "        \"\"\"\n",
    "        mask = self.get_mask(self.order, token)\n",
    "        ranks = generate_masked_orthogonal_rank_groups(self.world_size, self.ordered_size, mask)\n",
    "        if self.rank_offset > 0:\n",
    "            for rank_group in ranks:\n",
    "                for i in range(len(rank_group)):\n",
    "                    rank_group[i] += self.rank_offset\n",
    "        return ranks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da4ebc1",
   "metadata": {},
   "source": [
    "# 定义initialize_model_parallel函数\n",
    "`initialize_model_parallel`函数根据输入参数设置模型、张量、流水线、数据、专家和上下文并行组。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a5fc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model_parallel(\n",
    "    tensor_model_parallel_size: int = 1,\n",
    "    pipeline_model_parallel_size: int = 1,\n",
    "    context_parallel_size: int = 1,\n",
    "    expert_model_parallel_size: int = 1,\n",
    "    expert_tensor_parallel_size: Optional[int] = None,\n",
    "    order: str = \"tp-cp-ep-dp-pp\",\n",
    "    world_size: int = 1,\n",
    ") -> None:\n",
    "    decoder_model_size = (\n",
    "        tensor_model_parallel_size * pipeline_model_parallel_size * context_parallel_size\n",
    "    )\n",
    "    total_model_size = decoder_model_size\n",
    "    if world_size % total_model_size != 0:\n",
    "        raise RuntimeError(f\"world_size ({world_size}) is not divisible by {total_model_size}\")\n",
    "    data_parallel_size: int = world_size // total_model_size\n",
    "    decoder_world_size = decoder_model_size * data_parallel_size\n",
    "    encoder_rank_generator = None\n",
    "    decoder_rank_generator = RankGenerator(\n",
    "        tp=tensor_model_parallel_size,\n",
    "        ep=1,\n",
    "        dp=data_parallel_size,\n",
    "        pp=pipeline_model_parallel_size,\n",
    "        cp=context_parallel_size,\n",
    "        order=order,\n",
    "        rank_offset=0,\n",
    "    )\n",
    "    if expert_tensor_parallel_size is None:\n",
    "        expert_tensor_parallel_size = tensor_model_parallel_size\n",
    "    expert_tensor_model_pipeline_parallel_size = (\n",
    "        expert_tensor_parallel_size * expert_model_parallel_size * pipeline_model_parallel_size\n",
    "    )\n",
    "    expert_data_parallel_size = decoder_world_size // expert_tensor_model_pipeline_parallel_size\n",
    "    if decoder_world_size % expert_tensor_model_pipeline_parallel_size != 0:\n",
    "        raise RuntimeError(\n",
    "            f\"decoder world_size ({decoder_world_size}) is not divisible by expert_tensor_model_pipeline_parallel size ({expert_tensor_model_pipeline_parallel_size})\"\n",
    "        )\n",
    "    expert_decoder_rank_generator = RankGenerator(\n",
    "        tp=expert_tensor_parallel_size,\n",
    "        ep=expert_model_parallel_size,\n",
    "        dp=expert_data_parallel_size,\n",
    "        pp=pipeline_model_parallel_size,\n",
    "        cp=1,\n",
    "        order=order,\n",
    "        rank_offset=0,\n",
    "    )\n",
    "    def generator_wrapper(group_type, is_expert=False, **kwargs):\n",
    "        if is_expert:\n",
    "            d_ranks = expert_decoder_rank_generator.get_ranks(group_type, **kwargs)\n",
    "        else:\n",
    "            d_ranks = decoder_rank_generator.get_ranks(group_type, **kwargs)\n",
    "        if encoder_rank_generator is None:\n",
    "            for x in d_ranks:\n",
    "                yield x\n",
    "            return\n",
    "    # 给定并行配置，打印所有并行组\n",
    "    # DP groups\n",
    "    _DATA_PARALLEL_GROUP = [ranks for ranks in generator_wrapper('dp')]\n",
    "    print(f\"Data Parallel groups (DP): \\n{_DATA_PARALLEL_GROUP}\")\n",
    "    _DATA_PARALLEL_GROUP_WITH_CP = [ranks_with_cp for ranks_with_cp in generator_wrapper('dp-cp')]\n",
    "    print(f\"Data Parallel groups with cp (DP_with_cp): \\n{_DATA_PARALLEL_GROUP_WITH_CP}\")\n",
    "    # CP groups\n",
    "    _CONTEXT_PARALLEL_GROUP = [ranks for ranks in generator_wrapper('cp')]\n",
    "    print(f\"Context Parallel groups (CP): \\n{_CONTEXT_PARALLEL_GROUP}\")\n",
    "    # MP groups\n",
    "    _MODEL_PARALLEL_GROUP = [ranks for ranks in generator_wrapper('tp-pp')]\n",
    "    print(f\"Model Parallel groups (MP): \\n{_MODEL_PARALLEL_GROUP}\")\n",
    "    # TP groups\n",
    "    _TENSOR_MODEL_PARALLEL_GROUP = [ranks for ranks in generator_wrapper('tp')]\n",
    "    print(f\"Tensor Model Parallel groups (TP): \\n{_TENSOR_MODEL_PARALLEL_GROUP}\")\n",
    "    # PP groups\n",
    "    _PIPELINE_MODEL_PARALLEL_GROUP = [ranks for ranks in generator_wrapper('pp')]\n",
    "    print(f\"Pipeline Model Parallel groups (PP): \\n{_PIPELINE_MODEL_PARALLEL_GROUP}\")\n",
    "    # EP groups\n",
    "    _EXPERT_MODEL_PARALLEL_GROUP = [ranks for ranks in generator_wrapper('ep', is_expert=True)]\n",
    "    print(f\"Expert Model Parallel groups (EP): \\n{_EXPERT_MODEL_PARALLEL_GROUP}\")\n",
    "    # ETP groups\n",
    "    _EXPERT_TENSOR_PARALLEL_GROUP = [ranks for ranks in generator_wrapper('tp', is_expert=True)]\n",
    "    print(f\"Expert Tensor Parallel groups (ETP): \\n{_EXPERT_TENSOR_PARALLEL_GROUP}\")\n",
    "    # ETP+MP groups\n",
    "    _EXPERT_TENSOR_AND_MODEL_PARALLEL_GROUP = [ranks for ranks in generator_wrapper('tp-ep', is_expert=True)]\n",
    "    print(f\"Expert Tensor and Model Parallel groups: \\n{_EXPERT_TENSOR_AND_MODEL_PARALLEL_GROUP}\")\n",
    "    # ETP+MP+PP groups\n",
    "    _EXPERT_TENSOR_MODEL_PIPELINE_PARALLEL_GROUP = [ranks for ranks in generator_wrapper('tp-ep-pp', is_expert=True)]\n",
    "    print(f\"Expert Tensor Model Pipeline Parallel groups: \\n{_EXPERT_TENSOR_MODEL_PIPELINE_PARALLEL_GROUP}\")\n",
    "    # EDP groups\n",
    "    _EXPERT_DATA_PARALLEL_GROUP = [ranks for ranks in generator_wrapper('dp', is_expert=True)]\n",
    "    print(f\"Expert Data Parallel groups (EDP): \\n{_EXPERT_DATA_PARALLEL_GROUP}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d11e421",
   "metadata": {},
   "source": [
    "# 参数解析与初始化\n",
    "在笔记本中，我们手动为参数赋值，而不是使用命令行解析。这样可以方便地交互式实验不同的并行组配置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bca3b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example parameters for model parallel group initialization\n",
    "world_size = 8\n",
    "tensor_model_parallel_size = 2\n",
    "pipeline_model_parallel_size = 2\n",
    "context_parallel_size = 1\n",
    "expert_model_parallel_size = 1\n",
    "expert_tensor_parallel_size = None\n",
    "order = \"tp-pp-dp\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822ccb4f",
   "metadata": {},
   "source": [
    "# 模型并行组初始化模拟\n",
    "我们现在使用示例参数调用`initialize_model_parallel`函数，并展示生成的各类并行组。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d902ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Begin simulate model parallel group initialization...\")\n",
    "print(f\"world size: {world_size}, tp: {tensor_model_parallel_size}, pp: {pipeline_model_parallel_size}, ep: {expert_model_parallel_size}, etp: {expert_tensor_parallel_size}, cp: {context_parallel_size}\")\n",
    "initialize_model_parallel(\n",
    "    tensor_model_parallel_size=tensor_model_parallel_size,\n",
    "    pipeline_model_parallel_size=pipeline_model_parallel_size,\n",
    "    context_parallel_size=context_parallel_size,\n",
    "    expert_model_parallel_size=expert_model_parallel_size,\n",
    "    expert_tensor_parallel_size=expert_tensor_parallel_size,\n",
    "    world_size=world_size,\n",
    "    order=order,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
